{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "%pip install llama-index-llms\n",
    "%pip install llama-index-readers\n",
    "%pip install llama-index-embeddings\n",
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbedding\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.core import ( Settings, VectorStoreIndex, SimpleDirectoryReader)\n",
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "import chromadb\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "import datetime\n",
    "import numpy as np\n",
    "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, ExactMatchFilter\n",
    "from sqlalchemy import *\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "\n",
    "Settings.callback_manager = callback_manager\n",
    "\n",
    "load_dotenv('../Credentials/.env')\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "credential = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_api_version = \"2024-04-01-preview\"\n",
    "azure_openai_embedding_deployment = \"text-embedding-ada-002\"\n",
    "embedding_model_name = \"text-embedding-ada-002\"\n",
    "llm_model_name = \"gpt-35-turbo-16k\"\n",
    "api_type = \"azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_db = chromadb.HttpClient(host='localhost',port=8000)\n",
    "remote_db.delete_collection(\"quickstart\")\n",
    "chroma_collection = remote_db.get_or_create_collection(\"quickstart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data, Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"../Data/\", recursive=True, filename_as_id=True, required_exts=[\".pdf\", \".docx\", \".xlsx\", \".pptx\"])\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "documents = []\n",
    "for docs in reader.iter_data():\n",
    "    for filename in glob.glob('../Data/course*/course_file.json',recursive=True):\n",
    "        df = pd.read_json(filename)\n",
    "\n",
    "        file_metadata = df.loc[df['filename'] == docs[0].metadata['file_name'].replace('_','+')]\n",
    "        if file_metadata.empty != True:                \n",
    "            file_metadata = file_metadata.squeeze().to_dict()\n",
    "            file_metadata = pd.DataFrame(file_metadata, index=[0]).replace(np.NaN, 0).replace(0, None)\n",
    "            file_metadata = file_metadata.to_dict('records')[0]\n",
    "            folder = file_metadata.get('folder_id')\n",
    "        else:\n",
    "            file_metadata = {}\n",
    "            folder = ''\n",
    "            pass\n",
    "\n",
    "    for filename in glob.glob('../Data/course*/course_folder.json',recursive=True):\n",
    "        df = pd.read_json(filename)\n",
    "\n",
    "        folder_metadata = df.loc[df['id'] == folder]\n",
    "        if folder_metadata.empty != True:\n",
    "            folder_metadata = folder_metadata.squeeze().to_dict()\n",
    "            folder_metadata = pd.DataFrame(folder_metadata, index=[0]).replace(np.NaN, 0).replace(0, None)\n",
    "            folder_metadata = folder_metadata.to_dict('records')[0]\n",
    "            if 'Week' in folder_metadata['full_name']:\n",
    "                week = [i for i in folder_metadata['full_name'].split(\"/\") if 'Week' in i][0].replace('Week','').replace(' ','')\n",
    "                folder_metadata.update({\"week\":week})\n",
    "        else:\n",
    "            folder_metadata = {}\n",
    "            pass\n",
    "    \n",
    "    for filename in glob.glob('../Data/course*/course_course.json',recursive=True):\n",
    "        df = pd.read_json(filename)        \n",
    "        course_metadata = df.loc[df['id'] == folder_metadata.get('context_id')]\n",
    "        if course_metadata.empty != True:\n",
    "            course_metadata = course_metadata.squeeze().to_dict()\n",
    "            course_id = folder_metadata.get('context_id')\n",
    "        else:\n",
    "            course_metadata = {}\n",
    "            pass\n",
    "        \n",
    "    for doc in docs:\n",
    "        doc.metadata.update({\"file_id\": file_metadata.get('id'), \"folder_id\":file_metadata.get('folder_id'), \"display_name\":file_metadata.get('display_name')})\n",
    "        doc.metadata.update({\"week\": folder_metadata.get('week')})\n",
    "        doc.metadata.update({\"course_id\": course_metadata.get('id'), \"course_name\":course_metadata.get('name'),\"course_code\":course_metadata.get('course_code'),\"course_term\":course_metadata.get('term', {}).get('name')}) \n",
    "\n",
    "    documents.extend(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '1',\n",
       " 'file_name': '1-s2.0-S1538544221000821-main.pdf',\n",
       " 'file_path': '../Data/course113113/downloads/1-s2.0-S1538544221000821-main.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 719173,\n",
       " 'creation_date': '2024-04-16',\n",
       " 'last_modified_date': '2024-04-16',\n",
       " 'last_accessed_date': '2024-04-30',\n",
       " 'file_id': 19434347,\n",
       " 'folder_id': 3847349,\n",
       " 'display_name': '1-s2.0-S1538544221000821-main.pdf',\n",
       " 'week': '4',\n",
       " 'course_id': 131972,\n",
       " 'course_name': 'PWY 133: Integrated Human Pathophysiology II - HMS - 01/29/2024 - 03/15/2024',\n",
       " 'course_code': 'PWY 133',\n",
       " 'course_term': '2023-2024 Spring'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Parsing, Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_embedding ->  1.638826 seconds\n",
      "    |_embedding ->  0.70462 seconds\n",
      "    |_embedding ->  1.033021 seconds\n",
      "    |_embedding ->  0.682273 seconds\n",
      "    |_embedding ->  0.533042 seconds\n",
      "    |_embedding ->  0.438322 seconds\n",
      "    |_embedding ->  0.445663 seconds\n",
      "    |_embedding ->  0.709348 seconds\n",
      "    |_embedding ->  0.548527 seconds\n",
      "    |_embedding ->  0.446297 seconds\n",
      "    |_embedding ->  0.485594 seconds\n",
      "    |_embedding ->  0.62756 seconds\n",
      "    |_embedding ->  0.477588 seconds\n",
      "    |_embedding ->  0.449777 seconds\n",
      "    |_embedding ->  0.518441 seconds\n",
      "    |_embedding ->  0.416154 seconds\n",
      "    |_embedding ->  0.597191 seconds\n",
      "    |_embedding ->  0.824583 seconds\n",
      "    |_embedding ->  1.720888 seconds\n",
      "    |_embedding ->  0.617372 seconds\n",
      "    |_embedding ->  0.622606 seconds\n",
      "    |_embedding ->  0.588417 seconds\n",
      "    |_embedding ->  0.59923 seconds\n",
      "    |_embedding ->  0.563162 seconds\n",
      "    |_embedding ->  0.799817 seconds\n",
      "    |_embedding ->  0.505863 seconds\n",
      "    |_embedding ->  1.129638 seconds\n",
      "    |_embedding ->  0.535433 seconds\n",
      "    |_embedding ->  0.616103 seconds\n",
      "    |_embedding ->  0.526228 seconds\n",
      "    |_embedding ->  0.460801 seconds\n",
      "    |_embedding ->  0.460708 seconds\n",
      "    |_embedding ->  0.586515 seconds\n",
      "    |_embedding ->  0.500021 seconds\n",
      "    |_embedding ->  0.629317 seconds\n",
      "    |_embedding ->  0.222302 seconds\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "# set up ChromaVectorStore and load in data\n",
    "llm = AzureOpenAI(\n",
    "            model = llm_model_name,\n",
    "            deployment_name = llm_model_name,\n",
    "            api_key = credential,\n",
    "            azure_endpoint = endpoint,\n",
    "            api_version = azure_openai_api_version,\n",
    "            api_type = api_type\n",
    "        )\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "            model = embedding_model_name,\n",
    "            deployment_name = embedding_model_name,\n",
    "            api_key = credential,\n",
    "            azure_endpoint = endpoint,\n",
    "            api_version = azure_openai_api_version,\n",
    "            api_type = api_type,\n",
    "            embed_batch_size=50\n",
    "        )\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, embed_model=embed_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Persistent Storage\n",
    "\n",
    "In case you want to load your index later, saving you from having to re-parse your documents every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = chromadb.PersistentClient(path=\"../chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Query Engine, Ask a Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_query ->  1.504121 seconds\n",
      "      |_retrieve ->  0.286729 seconds\n",
      "        |_embedding ->  0.230248 seconds\n",
      "      |_synthesize ->  1.217181 seconds\n",
      "        |_templating ->  1.2e-05 seconds\n",
      "        |_llm ->  1.214584 seconds\n",
      "**********\n",
      "Question: If lifestyle modifications alone are not sufficient, which initial anti-hypertensive medication (or class of medications) would you choose? Explain your rationale.\n",
      "A) ACE inhibitors\n",
      "B) Beta blockers\n",
      "C) Calcium channel blockers\n",
      "D) Diuretics\n"
     ]
    }
   ],
   "source": [
    "# filters = MetadataFilters(\n",
    "#     filters=[MetadataFilter(key=\"course_id\", value=131972)]\n",
    "# )\n",
    "\n",
    "filters = MetadataFilters(filters=[\n",
    "    MetadataFilter(\n",
    "        key=\"course_id\", \n",
    "        value=131972\n",
    "    ),\n",
    "     MetadataFilter(\n",
    "        key=\"week\", \n",
    "        value='2'\n",
    "    ),\n",
    "])\n",
    "\n",
    "query_engine = index.as_query_engine(filters=filters)\n",
    "response = query_engine.query(\"Give me a multiple choice question from the context\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
