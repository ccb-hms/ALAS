{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-readers-wikipedia\n",
    "%pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "from llama_index.core import SQLDatabase\n",
    "import logging\n",
    "import sys\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.tools import ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL database create goes here\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    column,\n",
    "    insert\n",
    ")\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\", future=True)\n",
    "metadata_obj = MetaData()\n",
    "\n",
    "# create city SQL table\n",
    "table_name = \"city_stats\"\n",
    "city_stats_table = Table(\n",
    "    table_name,\n",
    "    metadata_obj,\n",
    "    Column(\"city_name\", String(16), primary_key=True),\n",
    "    Column(\"population\", Integer),\n",
    "    Column(\"country\", String(16), nullable=False),\n",
    ")\n",
    "\n",
    "metadata_obj.create_all(engine)\n",
    "\n",
    "rows = [\n",
    "    {\"city_name\": \"Toronto\", \"population\": 2930000, \"country\": \"Canada\"},\n",
    "    {\"city_name\": \"Tokyo\", \"population\": 13960000, \"country\": \"Japan\"},\n",
    "    {\"city_name\": \"Berlin\", \"population\": 3645000, \"country\": \"Germany\"},\n",
    "]\n",
    "for row in rows:\n",
    "    stmt = insert(city_stats_table).values(**row)\n",
    "    with engine.begin() as connection:\n",
    "        cursor = connection.execute(stmt)\n",
    "        \n",
    "with engine.connect() as connection:\n",
    "    cursor = connection.exec_driver_sql(\"SELECT * FROM city_stats\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build SQL index\n",
    "sql_database = SQLDatabase(engine, include_tables=[\"city_stats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build vector index\n",
    "\n",
    "# Insert documents into vector index\n",
    "# Each document has metadata of the city attached\n",
    "\n",
    "vector_indices = {}\n",
    "vector_query_engines = {}\n",
    "\n",
    "for city, wiki_doc in zip(cities, wiki_docs):\n",
    "    vector_index = VectorStoreIndex.from_documents([wiki_doc])\n",
    "    # modify default llm to be gpt-3.5 for quick/cheap queries\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2, llm=OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    )\n",
    "    vector_indices[city] = vector_index\n",
    "    vector_query_engines[city] = query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define query engines, set as tools\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"city_stats\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = []\n",
    "for city in cities:\n",
    "    query_engine = vector_query_engines[city]\n",
    "\n",
    "    query_engine_tool = QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=city, description=f\"Provides information about {city}\"\n",
    "        ),\n",
    "    )\n",
    "    query_engine_tools.append(query_engine_tool)\n",
    "\n",
    "\n",
    "s_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools, llm=OpenAI(model=\"gpt-3.5-turbo\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# vector_store_info = VectorStoreInfo(\n",
    "#     content_info='articles about different cities',\n",
    "#     metadata_info=[\n",
    "#         MetadataInfo(\n",
    "#             name='title',\n",
    "#             type='str',\n",
    "#             description='The name of the city'),\n",
    "#     ]\n",
    "# )\n",
    "# vector_auto_retriever = VectorIndexAutoRetriever(vector_index, vector_store_info=vector_store_info, llm=OpenAI(model='gpt-4')\n",
    "\n",
    "# retriever_query_engine = RetrieverQueryEngine.from_args(\n",
    "#     vector_auto_retriever, llm=OpenAI(model='gpt-3.5-turbo')\n",
    "# )\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query over\"\n",
    "        \" a table containing: city_stats, containing the population/country of\"\n",
    "        \" each city\"\n",
    "    ),\n",
    ")\n",
    "s_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=s_engine,\n",
    "    description=(\n",
    "        f\"Useful for answering semantic questions about different cities\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define SQLJoinQueryEngine\n",
    "from llama_index.core.query_engine import SQLJoinQueryEngine\n",
    "\n",
    "query_engine = SQLJoinQueryEngine(\n",
    "    sql_tool, s_engine_tool, llm=OpenAI(model=\"gpt-4\")\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"Tell me about the arts and culture of the city with the highest\"\n",
    "    \" population\"\n",
    ")\n",
    "\n",
    "print(str(response))\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"Compare and contrast the demographics of Berlin and Toronto\"\n",
    ")\n",
    "\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
